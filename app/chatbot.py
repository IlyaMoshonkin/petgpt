from operator import itemgetter
import os

from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_models import ChatYandexGPT
from langchain_community.embeddings import GigaChatEmbeddings, YandexGPTEmbeddings
from langchain_community.chat_models import GigaChat
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.globals import set_debug

# set_debug(True)

from promts import main_promt


import streamlit as st
import os

# from generate_token import generate_token

# —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ streamlit
def main():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ—Ç–∏–ø–∞ –∫–æ–º–ø–∞–Ω–∏–∏
    logo_image = 'app/images/logo-2.jpg'  # –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ª–æ–≥–æ—Ç–∏–ø–∞

    # # # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–æ–≥–æ—Ç–∏–ø–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    from PIL import Image
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ—Ç–∏–ø–∞
    logo = Image.open(logo_image)
    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ª–æ–≥–æ—Ç–∏–ø–∞
    resized_logo = logo.resize((200, 150))
    st.set_page_config(page_title="PetPalsGPT", page_icon="üìñ")   
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ª–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–≥–æ –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    st.image(resized_logo)
    st.title('üìñ PetPalsGPT')
    """
    –ß–∞—Ç–±–æ—Ç –Ω–∞ –±–∞–∑–µ GPT, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã. –ß—Ç–æ–±—ã "—Å–±—Ä–æ—Å–∏—Ç—å" –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –±—Ä–∞—É–∑–µ—Ä–∞.\n
    –í—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.
    """
    # st.warning('–≠—Ç–æ Playground –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å YandexGPT')

    # –≤–≤–æ–¥–∏—Ç—å –≤—Å–µ credentials –≤ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ —Å–ª–µ–≤–∞
    # Sidebar contents
    with st.sidebar:
        st.title('\U0001F917\U0001F4AC PetPalsGPT —á–∞—Ç–±–æ—Ç')
        st.markdown('''
        ## –û –ø—Ä–æ–≥—Ä–∞–º–º–µ
        –î–∞–Ω–Ω—ã–π —á–∞—Ç–±–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
        - [Streamlit](https://streamlit.io/)
        - [LangChain](https://python.langchain.com/)
        ''')

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ä–∞–±–æ—Ç—ã –ø–∞–º—è—Ç–∏
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    if len(msgs.messages) == 0:
        msgs.add_ai_message("–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –æ –¥–æ–º–∞—à–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å —Å–µ–≥–æ–¥–Ω—è?")

    view_messages = st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π")


    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ .env
    # load_dotenv()
    yc_folder_id = st.secrets.get("YC_FOLDER_ID")

    if not yc_folder_id:
        yc_folder_id = st.sidebar.text_input("YC folder ID", type="password")
        if not yc_folder_id:
            st.info("–£–∫–∞–∂–∏—Ç–µ [YC folder ID](https://cloud.yandex.ru/ru/docs/yandexgpt/quickstart#yandex-account_1) –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —á–∞—Ç–±–æ—Ç–∞")
            st.stop()

    
        
    yc_iam_token = st.sidebar.text_input("YC IAM token", type="password")
    if not yc_iam_token:
        st.info("–£–∫–∞–∂–∏—Ç–µ [YC IAM token](https://cloud.yandex.ru/ru/docs/yandexgpt/quickstart#yandex-account_1) –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —á–∞—Ç–±–æ—Ç–∞")
        st.stop()
        
    
    # yagpt_folder_id = st.secrets["YC_FOLDER_ID"]
    # yc_service_account_id = st.secrets["YC_SERVICE_ACCOUNT_ID"]
    # yc_key_id = st.secrets["YC_KEY_ID"]
    # yc_private_key = st.secrets["YC_PRIVATE_KEY"]
    # yc_private_key = load_private_key(".streamlit/private_key.pem", "your_password")
    # yc_iam_token = generate_token('.streamlit/sa-gen-petpals-gpt-00001.json')
    gigachat_credintials = st.secrets["GIGACHAT_CREDENTIALS"]
     

    # with st.sidebar:
    #     st.markdown('''
    #         ## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    #         –ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å, —Å—Ç–µ–ø–µ–Ω—å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    #         ''')

    model_dict = {
      "YandexGPT Lite": "gpt://b1gr0nm9o4sp7b51etoh/yandexgpt-lite/latest",
      "YandexGPT Lite RC": "gpt://b1gr0nm9o4sp7b51etoh/yandexgpt-lite/rc",
      "YandexGPT Pro": "gpt://b1gr0nm9o4sp7b51etoh/yandexgpt/latest",
      "GigaChat LIte": "GigaChat",
      "GigaChat Lite+": "GigaChat-Plus",
      "GigaChat Pro": "GigaChat-Pro",
    }
    index_model = 0
    # selected_model = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã:", model_dict.keys(), index=index_model, key="index" ) 
    selected_model = "YandexGPT Pro"
    
    # yagpt_prompt = st.sidebar.text_input("–ü—Ä–æ–º–ø—Ç-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è YaGPT")
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ü–∏–∏
    # prompt_option = st.sidebar.selectbox(
    #     '–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å',
    #     ('–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é', 
    #      #'–ó–∞–¥–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ'
    #      )
    
    default_prompt = main_promt
    # # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –æ–ø—Ü–∏—è "–ó–∞–¥–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ", –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞
    # if prompt_option == '–ó–∞–¥–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ':
    #     custom_prompt = st.sidebar.text_input('–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç:')
    # else:
    #     custom_prompt = default_prompt
    #     # st.sidebar.write(custom_prompt)
    #     with st.sidebar:
    #         st.code(custom_prompt)
    # # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ "–∑–∞–¥–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ" –∏ –Ω–µ –∑–∞–¥–∞–ª–∏, —Ç–æ –±–µ—Ä–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    # if len(custom_prompt)==0: custom_prompt = default_prompt
    custom_prompt = default_prompt

    # temperature = st.sidebar.slider("–°—Ç–µ–ø–µ–Ω—å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞)", 0.0, 1.0, 0.6)
    temperature = 0.3
    # yagpt_max_tokens = st.sidebar.slider("–†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ (–≤ [—Ç–æ–∫–µ–Ω–∞—Ö](https://cloud.yandex.ru/ru/docs/yandexgpt/concepts/tokens))", 200, 8000, 5000)

    def history_reset_function():
        # Code to be executed when the reset button is clicked
        st.session_state.clear()

    st.sidebar.button("–û–±–Ω—É–ª–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –æ–±—â–µ–Ω–∏—è", on_click=history_reset_function)
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LangChain, –ø–µ—Ä–µ–¥–∞–≤–∞—è Message History
    # –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—â–µ–Ω–∏—è

    if selected_model.startswith("GigaChat"):
        model = GigaChat(
            credentials=gigachat_credintials,
            verify_ssl_certs=False, scope="GIGACHAT_API_CORP", name=selected_model, temperature = temperature, #max_tokens = yagpt_max_tokens
                         )
        embeddings = GigaChatEmbeddings(verify_ssl_certs=False, scope="GIGACHAT_API_CORP")
        index = FAISS.load_local("app/index/index_chunk_1000-chars_embeddings_giga_chat", embeddings, allow_dangerous_deserialization=True)
    else:
        model_uri = model_dict[selected_model]
        model = ChatYandexGPT(
            iam_token=yc_iam_token,
            model_uri=model_uri,
            temperature=temperature,  
            # max_tokens = yagpt_max_tokens
        )
        emb_model_uri = "emb://b1gr0nm9o4sp7b51etoh/text-search-doc/latest"
        embeddings = YandexGPTEmbeddings(
            iam_token=yc_iam_token, model_uri=emb_model_uri, folder_id=yc_folder_id
        )
        index = FAISS.load_local(
            "app/index/index_chunk_1000-chars_embeddings_ya-text-search-doc-v2",
            embeddings,
            allow_dangerous_deserialization=True,
        )

    
    combined_prompt = ChatPromptTemplate.from_messages([
    ("system", custom_prompt),
    MessagesPlaceholder(variable_name="history"),
    ("human", """
    –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ —Ç–µ–∫—Å—Ç –Ω–∏–∂–µ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –≤–æ–ø—Ä–æ—Å—É, –∞ —Ç–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞—è –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    
    –¢–µ–∫—Å—Ç:
    -----
    {context}
    -----
    
    –í–æ–ø—Ä–æ—Å: {question}
    """)
    ])
    
    def get_question(input):
        if not input:
            return None
        elif isinstance(input,str):
            return input
        elif isinstance(input,dict) and 'question' in input:
            return input['question']
        elif isinstance(input,BaseMessage):
            return input.content
        else:
            raise Exception("string or dict with 'question' key expected as RAG chain input.")

    from langchain.schema import AIMessage, HumanMessage
    
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    retriever = index.as_retriever(search_kwargs = {"k": 10})

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É
    chain = (
        {
            "context": RunnableLambda(get_question) | retriever | format_docs, 
            "question": RunnablePassthrough(),
            "history": lambda x: x["history"]
        }
        | combined_prompt
        | model
        | StrOutputParser()
    )

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    chain_with_history = RunnableWithMessageHistory(
        chain,
        lambda session_id: msgs,
        input_messages_key="question",
        history_messages_key="history",
    )

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ StreamlitChatMessageHistory
    for msg in msgs.messages:
        st.chat_message(msg.type).write(msg.content)

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç –Ω–æ–≤–æ–µ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    if prompt := st.chat_input():
        st.chat_message("human").write(prompt)
        config = {"configurable": {"session_id": "any"}}
        response = chain_with_history.invoke({"question": prompt}, config)
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø response –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        if isinstance(response, AIMessage):
            st.chat_message("ai").write(response.content)
        elif isinstance(response, str):
            st.chat_message("ai").write(response)
        else:
            st.chat_message("ai").write(str(response))

    # –û—Ç–æ–±—Ä–∞–∑–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ, —á—Ç–æ–±—ã –≤–Ω–æ–≤—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å —Å—Ä–∞–∑—É
    with view_messages:
        """
        –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å –ø–æ–º–æ—â—å—é:
        ```python
        msgs = StreamlitChatMessageHistory(key="langchain_messages")
        ```

        –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ `st.session_state.langchain_messages`:
        """
        view_messages.json(st.session_state.langchain_messages)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.write(f"–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–±–æ—Ç—ã. {str(e)}")